import matplotlib.pyplot as plt
import numpy as np

def gradientDescendent(f, p, lr=0.01, max_loops=1000, dump_period=100):
    """
    梯度下降算法
    :param f: 目標函數
    :param p: 參數列表
    :param lr: 學習率
    :param max_loops: 最大迭代次數
    :param dump_period: 記錄周期
    :return: 優化後的參數
    """
    for loop in range(max_loops):
        # 計算當前參數的損失
        loss = f(p)

        # 計算每個參數的梯度
        grads = []
        for i in range(len(p)):
            orig_value = p[i]
            p[i] = orig_value + 1e-5
            loss_plus = f(p)
            p[i] = orig_value - 1e-5
            loss_minus = f(p)
            p[i] = orig_value
            grad = (loss_plus - loss_minus) / (2 * 1e-5)
            grads.append(grad)

        # 更新參數
        for i in range(len(p)):
            p[i] -= lr * grads[i]

        # 打印損失
        if loop % dump_period == 0:
            print(f"Loop {loop}, Loss: {loss}")

    return p

def f(p):
    [x, y, z] = p
    return (x-1)**2 + (y-2)**2 + (z-3)**2
    # return (x-2)**2 + 3*(y-0.5)**2 + (z-2.5)**2
    # return x*x + 3*y*y + z*z - 4*x - 3*y - 5*z + 8

p = [0.0, 0.0, 0.0]
print("Optimizing function f with initial parameters:", p)
optimized_p = gradientDescendent(f, p)
print("Optimized parameters for f:", optimized_p)

x = np.array([0, 1, 2, 3, 4], dtype=np.float32)
y = np.array([1.9, 3.1, 3.9, 5.0, 6.2], dtype=np.float32)

def predict(a, xt):
    return a[0] + a[1] * xt

def MSE(a, x, y):
    total = 0
    for i in range(len(x)):
        total += (y[i] - predict(a, x[i])) ** 2
    return total

def loss(p):
    return MSE(p, x, y)

p = [0.0, 0.0]
print("Optimizing linear regression parameters with initial parameters:", p)
plearn = gradientDescendent(loss, p, max_loops=3000, dump_period=100)
print("Optimized parameters for linear regression:", plearn)

# 繪製圖形
y_predicted = list(map(lambda t: plearn[0] + plearn[1] * t, x))
print('y_predicted =', y_predicted)
plt.plot(x, y, 'ro', label='Original data')
plt.plot(x, y_predicted, label='Fitted line')
plt.legend()
plt.show()
